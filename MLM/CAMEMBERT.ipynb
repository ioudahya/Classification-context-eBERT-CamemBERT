{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CAMEMBERT.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP2HbcP0CZAdR0C9+UKX5SC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RSh9PZM6pWgW","executionInfo":{"status":"ok","timestamp":1652016789559,"user_tz":-120,"elapsed":129189,"user":{"displayName":"Hika Chou","userId":"12770496042228956078"}},"outputId":"6c13aa28-3159-42b8-e11b-e096d244aaf0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (2019.12.20)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n","Requirement already satisfied: hydra-core in /usr/local/lib/python3.7/dist-packages (1.1.2)\n","Requirement already satisfied: antlr4-python3-runtime==4.8 in /usr/local/lib/python3.7/dist-packages (from hydra-core) (4.8)\n","Requirement already satisfied: importlib-resources<5.3 in /usr/local/lib/python3.7/dist-packages (from hydra-core) (5.2.3)\n","Requirement already satisfied: omegaconf==2.1.* in /usr/local/lib/python3.7/dist-packages (from hydra-core) (2.1.2)\n","Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.7/dist-packages (from omegaconf==2.1.*->hydra-core) (6.0)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources<5.3->hydra-core) (3.8.0)\n","Requirement already satisfied: omegaconf in /usr/local/lib/python3.7/dist-packages (2.1.2)\n","Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.7/dist-packages (from omegaconf) (6.0)\n","Requirement already satisfied: antlr4-python3-runtime==4.8 in /usr/local/lib/python3.7/dist-packages (from omegaconf) (4.8)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (2019.12.20)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (2.23.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests) (2.10)\n","Requirement already satisfied: bitarray in /usr/local/lib/python3.7/dist-packages (2.5.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.11.0+cu113)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.2.0)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n","Requirement already satisfied: sacrebleu in /usr/local/lib/python3.7/dist-packages (2.0.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from sacrebleu) (1.21.6)\n","Requirement already satisfied: portalocker in /usr/local/lib/python3.7/dist-packages (from sacrebleu) (2.4.0)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu) (0.8.9)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacrebleu) (2019.12.20)\n","Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from sacrebleu) (0.4.4)\n","Requirement already satisfied: dataclasses in /usr/local/lib/python3.7/dist-packages (0.6)\n","Collecting xformers\n","  Downloading xformers-0.0.10.tar.gz (196 kB)\n","\u001b[K     |████████████████████████████████| 196 kB 5.1 MB/s \n","\u001b[?25hRequirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from xformers) (1.11.0+cu113)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from xformers) (1.21.6)\n","Collecting pyre-extensions==0.0.23\n","  Downloading pyre_extensions-0.0.23-py3-none-any.whl (11 kB)\n","Collecting typing-inspect\n","  Downloading typing_inspect-0.7.1-py3-none-any.whl (8.4 kB)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from pyre-extensions==0.0.23->xformers) (4.2.0)\n","Collecting mypy-extensions>=0.3.0\n","  Downloading mypy_extensions-0.4.3-py2.py3-none-any.whl (4.5 kB)\n","Building wheels for collected packages: xformers\n","  Building wheel for xformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for xformers: filename=xformers-0.0.10-cp37-cp37m-linux_x86_64.whl size=4154083 sha256=b9bfc5116e52e68d2aabb28a6e403cda6aa701f36be7949f66dabc3ef8c1f4ba\n","  Stored in directory: /root/.cache/pip/wheels/50/6c/84/d15322f5b64dca00a4cbbead3d5e217533ac437acb0400a16d\n","Successfully built xformers\n","Installing collected packages: mypy-extensions, typing-inspect, pyre-extensions, xformers\n","Successfully installed mypy-extensions-0.4.3 pyre-extensions-0.0.23 typing-inspect-0.7.1 xformers-0.0.10\n","Collecting fairseq\n","  Downloading fairseq-0.10.2-cp37-cp37m-manylinux1_x86_64.whl (1.7 MB)\n","\u001b[K     |████████████████████████████████| 1.7 MB 5.1 MB/s \n","\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from fairseq) (2019.12.20)\n","Requirement already satisfied: dataclasses in /usr/local/lib/python3.7/dist-packages (from fairseq) (0.6)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fairseq) (1.21.6)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from fairseq) (4.64.0)\n","Requirement already satisfied: hydra-core in /usr/local/lib/python3.7/dist-packages (from fairseq) (1.1.2)\n","Requirement already satisfied: cffi in /usr/local/lib/python3.7/dist-packages (from fairseq) (1.15.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from fairseq) (1.11.0+cu113)\n","Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from fairseq) (0.29.28)\n","Requirement already satisfied: sacrebleu>=1.4.12 in /usr/local/lib/python3.7/dist-packages (from fairseq) (2.0.0)\n","Requirement already satisfied: portalocker in /usr/local/lib/python3.7/dist-packages (from sacrebleu>=1.4.12->fairseq) (2.4.0)\n","Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from sacrebleu>=1.4.12->fairseq) (0.4.4)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu>=1.4.12->fairseq) (0.8.9)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi->fairseq) (2.21)\n","Requirement already satisfied: importlib-resources<5.3 in /usr/local/lib/python3.7/dist-packages (from hydra-core->fairseq) (5.2.3)\n","Requirement already satisfied: antlr4-python3-runtime==4.8 in /usr/local/lib/python3.7/dist-packages (from hydra-core->fairseq) (4.8)\n","Requirement already satisfied: omegaconf==2.1.* in /usr/local/lib/python3.7/dist-packages (from hydra-core->fairseq) (2.1.2)\n","Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.7/dist-packages (from omegaconf==2.1.*->hydra-core->fairseq) (6.0)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources<5.3->hydra-core->fairseq) (3.8.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->fairseq) (4.2.0)\n","Installing collected packages: fairseq\n","Successfully installed fairseq-0.10.2\n"]}],"source":["!pip install regex sentencepiece\n","!pip install hydra-core\n","!pip install omegaconf\n","!pip install regex\n","!pip install requests\n","!pip install bitarray\n","!pip install torch\n","!pip install sentencepiece\n","!pip install sacrebleu\n","!pip install dataclasses\n","!pip install xformers\n","!pip install fairseq"]},{"cell_type":"code","source":["!python3 -c 'import torch' && echo \"Victoire\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wPslYVCHsnqg","executionInfo":{"status":"ok","timestamp":1652016790878,"user_tz":-120,"elapsed":1328,"user":{"displayName":"Hika Chou","userId":"12770496042228956078"}},"outputId":"a8200e09-11f1-447a-b7dc-c34c283c631e"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Victoire\n"]}]},{"cell_type":"code","source":["import torch\n","camembert = torch.hub.load('pytorch/fairseq', 'camembert')\n","camembert.eval()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8jEKxAKYpt8e","executionInfo":{"status":"ok","timestamp":1652016936203,"user_tz":-120,"elapsed":145328,"user":{"displayName":"Hika Chou","userId":"12770496042228956078"}},"outputId":"721cfba8-dec9-4e1d-fd3a-59d88f66b3de"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/pytorch/fairseq/archive/main.zip\" to /root/.cache/torch/hub/main.zip\n","2022-05-08 13:33:14 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n","2022-05-08 13:33:14 | WARNING | root | Triton is not available, some optimizations will not be enabled.\n","Error No module named 'triton'\n"]},{"output_type":"stream","name":"stdout","text":["No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n","running build_ext\n","cythoning fairseq/data/data_utils_fast.pyx to fairseq/data/data_utils_fast.cpp\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/cpp_extension.py:387: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n","  warnings.warn(msg.format('we could not find ninja.'))\n"]},{"output_type":"stream","name":"stdout","text":["cythoning fairseq/data/token_block_utils_fast.pyx to fairseq/data/token_block_utils_fast.cpp\n","building 'fairseq.libbleu' extension\n","creating build\n","creating build/temp.linux-x86_64-3.7\n","creating build/temp.linux-x86_64-3.7/fairseq\n","creating build/temp.linux-x86_64-3.7/fairseq/clib\n","creating build/temp.linux-x86_64-3.7/fairseq/clib/libbleu\n","x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/include/python3.7m -c fairseq/clib/libbleu/libbleu.cpp -o build/temp.linux-x86_64-3.7/fairseq/clib/libbleu/libbleu.o -std=c++11 -O3 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=libbleu -D_GLIBCXX_USE_CXX11_ABI=0\n","x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/include/python3.7m -c fairseq/clib/libbleu/module.cpp -o build/temp.linux-x86_64-3.7/fairseq/clib/libbleu/module.o -std=c++11 -O3 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=libbleu -D_GLIBCXX_USE_CXX11_ABI=0\n","creating build/lib.linux-x86_64-3.7\n","creating build/lib.linux-x86_64-3.7/fairseq\n","x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 -Wl,-Bsymbolic-functions -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.7/fairseq/clib/libbleu/libbleu.o build/temp.linux-x86_64-3.7/fairseq/clib/libbleu/module.o -o build/lib.linux-x86_64-3.7/fairseq/libbleu.cpython-37m-x86_64-linux-gnu.so\n","building 'fairseq.data.data_utils_fast' extension\n","creating build/temp.linux-x86_64-3.7/fairseq/data\n","x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/numpy/core/include -I/usr/local/lib/python3.7/dist-packages/numpy/core/include -I/usr/include/python3.7m -c fairseq/data/data_utils_fast.cpp -o build/temp.linux-x86_64-3.7/fairseq/data/data_utils_fast.o -std=c++11 -O3 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=data_utils_fast -D_GLIBCXX_USE_CXX11_ABI=0\n","creating build/lib.linux-x86_64-3.7/fairseq/data\n","x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 -Wl,-Bsymbolic-functions -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.7/fairseq/data/data_utils_fast.o -o build/lib.linux-x86_64-3.7/fairseq/data/data_utils_fast.cpython-37m-x86_64-linux-gnu.so\n","building 'fairseq.data.token_block_utils_fast' extension\n","x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/numpy/core/include -I/usr/local/lib/python3.7/dist-packages/numpy/core/include -I/usr/include/python3.7m -c fairseq/data/token_block_utils_fast.cpp -o build/temp.linux-x86_64-3.7/fairseq/data/token_block_utils_fast.o -std=c++11 -O3 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=token_block_utils_fast -D_GLIBCXX_USE_CXX11_ABI=0\n","x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 -Wl,-Bsymbolic-functions -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.7/fairseq/data/token_block_utils_fast.o -o build/lib.linux-x86_64-3.7/fairseq/data/token_block_utils_fast.cpython-37m-x86_64-linux-gnu.so\n","building 'fairseq.libbase' extension\n","creating build/temp.linux-x86_64-3.7/fairseq/clib/libbase\n","x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/include/python3.7m -c fairseq/clib/libbase/balanced_assignment.cpp -o build/temp.linux-x86_64-3.7/fairseq/clib/libbase/balanced_assignment.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=libbase -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n","x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 -Wl,-Bsymbolic-functions -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.7/fairseq/clib/libbase/balanced_assignment.o -L/usr/local/lib/python3.7/dist-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.7/fairseq/libbase.cpython-37m-x86_64-linux-gnu.so\n","building 'fairseq.libnat' extension\n","creating build/temp.linux-x86_64-3.7/fairseq/clib/libnat\n","x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/include/python3.7m -c fairseq/clib/libnat/edit_dist.cpp -o build/temp.linux-x86_64-3.7/fairseq/clib/libnat/edit_dist.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=libnat -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n","x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 -Wl,-Bsymbolic-functions -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.7/fairseq/clib/libnat/edit_dist.o -L/usr/local/lib/python3.7/dist-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.7/fairseq/libnat.cpython-37m-x86_64-linux-gnu.so\n","building 'alignment_train_cpu_binding' extension\n","creating build/temp.linux-x86_64-3.7/examples\n","creating build/temp.linux-x86_64-3.7/examples/operators\n","x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/include/python3.7m -c examples/operators/alignment_train_cpu.cpp -o build/temp.linux-x86_64-3.7/examples/operators/alignment_train_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=alignment_train_cpu_binding -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n","x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 -Wl,-Bsymbolic-functions -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.7/examples/operators/alignment_train_cpu.o -L/usr/local/lib/python3.7/dist-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.7/alignment_train_cpu_binding.cpython-37m-x86_64-linux-gnu.so\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-08 13:34:41 | INFO | root | Generating grammar tables from /usr/lib/python3.7/lib2to3/Grammar.txt\n","2022-05-08 13:34:41 | INFO | root | Generating grammar tables from /usr/lib/python3.7/lib2to3/PatternGrammar.txt\n"]},{"output_type":"stream","name":"stdout","text":["copying build/lib.linux-x86_64-3.7/fairseq/libbleu.cpython-37m-x86_64-linux-gnu.so -> fairseq\n","copying build/lib.linux-x86_64-3.7/fairseq/data/data_utils_fast.cpython-37m-x86_64-linux-gnu.so -> fairseq/data\n","copying build/lib.linux-x86_64-3.7/fairseq/data/token_block_utils_fast.cpython-37m-x86_64-linux-gnu.so -> fairseq/data\n","copying build/lib.linux-x86_64-3.7/fairseq/libbase.cpython-37m-x86_64-linux-gnu.so -> fairseq\n","copying build/lib.linux-x86_64-3.7/fairseq/libnat.cpython-37m-x86_64-linux-gnu.so -> fairseq\n","copying build/lib.linux-x86_64-3.7/alignment_train_cpu_binding.cpython-37m-x86_64-linux-gnu.so -> \n"]},{"output_type":"stream","name":"stderr","text":["2022-05-08 13:34:42 | INFO | fairseq.file_utils | http://dl.fbaipublicfiles.com/fairseq/models/camembert-base.tar.gz not found in cache, downloading to /tmp/tmpx0b8bmqn\n","100%|██████████| 1012630426/1012630426 [00:22<00:00, 44368976.33B/s]\n","2022-05-08 13:35:05 | INFO | fairseq.file_utils | copying /tmp/tmpx0b8bmqn to cache at /root/.cache/torch/pytorch_fairseq/3a5b985f6506f03df591fc4564446205fffa6bfe1a5d4657775ed20efdf3162b.4f0d00e7c3a06d48868273ae5e32b16aeb9cafa08939dd691352a8bdae6059be\n","2022-05-08 13:35:09 | INFO | fairseq.file_utils | creating metadata file for /root/.cache/torch/pytorch_fairseq/3a5b985f6506f03df591fc4564446205fffa6bfe1a5d4657775ed20efdf3162b.4f0d00e7c3a06d48868273ae5e32b16aeb9cafa08939dd691352a8bdae6059be\n","2022-05-08 13:35:09 | INFO | fairseq.file_utils | removing temp file /tmp/tmpx0b8bmqn\n","2022-05-08 13:35:09 | INFO | fairseq.file_utils | loading archive file http://dl.fbaipublicfiles.com/fairseq/models/camembert-base.tar.gz from cache at /root/.cache/torch/pytorch_fairseq/3a5b985f6506f03df591fc4564446205fffa6bfe1a5d4657775ed20efdf3162b.4f0d00e7c3a06d48868273ae5e32b16aeb9cafa08939dd691352a8bdae6059be\n","2022-05-08 13:35:09 | INFO | fairseq.file_utils | extracting archive file /root/.cache/torch/pytorch_fairseq/3a5b985f6506f03df591fc4564446205fffa6bfe1a5d4657775ed20efdf3162b.4f0d00e7c3a06d48868273ae5e32b16aeb9cafa08939dd691352a8bdae6059be to temp dir /tmp/tmpev9w2i1o\n","/usr/local/lib/python3.7/dist-packages/hydra/experimental/initialize.py:36: UserWarning: hydra.experimental.initialize() is no longer experimental. Use hydra.initialize()\n","  message=\"hydra.experimental.initialize() is no longer experimental.\"\n","/usr/local/lib/python3.7/dist-packages/hydra/experimental/compose.py:19: UserWarning: hydra.experimental.compose() is no longer experimental. Use hydra.compose()\n","  message=\"hydra.experimental.compose() is no longer experimental.\"\n","/usr/local/lib/python3.7/dist-packages/hydra/core/default_element.py:126: UserWarning: In 'config': Usage of deprecated keyword in package header '# @package _group_'.\n","See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/changes_to_package_header for more information\n","  See {url} for more information\"\"\"\n","/root/.cache/torch/hub/pytorch_fairseq_main/fairseq/checkpoint_utils.py:421: UserWarning: \n","'config' is validated against ConfigStore schema with the same name.\n","This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.\n","See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.\n","  state = load_checkpoint_to_cpu(filename, arg_overrides)\n","/usr/local/lib/python3.7/dist-packages/hydra/compose.py:54: UserWarning: \n","The strict flag in the compose API is deprecated and will be removed in the next version of Hydra.\n","See https://hydra.cc/docs/upgrades/0.11_to_1.0/strict_mode_flag_deprecated for more info.\n","\n","  \"\"\"\n","/usr/local/lib/python3.7/dist-packages/hydra/experimental/initialize.py:36: UserWarning: hydra.experimental.initialize() is no longer experimental. Use hydra.initialize()\n","  message=\"hydra.experimental.initialize() is no longer experimental.\"\n","/root/.cache/torch/hub/pytorch_fairseq_main/fairseq/models/roberta/model_camembert.py:48: UserWarning: \n","'config' is validated against ConfigStore schema with the same name.\n","This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.\n","See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.\n","  **kwargs,\n","2022-05-08 13:35:31 | INFO | fairseq.tasks.masked_lm | dictionary: 32004 types\n"]},{"output_type":"execute_result","data":{"text/plain":["RobertaHubInterface(\n","  (model): RobertaModel(\n","    (encoder): RobertaEncoder(\n","      (sentence_encoder): TransformerEncoder(\n","        (dropout_module): FairseqDropout()\n","        (embed_tokens): Embedding(32005, 768, padding_idx=1)\n","        (embed_positions): LearnedPositionalEmbedding(514, 768, padding_idx=1)\n","        (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (layers): ModuleList(\n","          (0): TransformerEncoderLayerBase(\n","            (self_attn): MultiheadAttention(\n","              (dropout_module): FairseqDropout()\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout_module): FairseqDropout()\n","            (activation_dropout_module): FairseqDropout()\n","            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          )\n","          (1): TransformerEncoderLayerBase(\n","            (self_attn): MultiheadAttention(\n","              (dropout_module): FairseqDropout()\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout_module): FairseqDropout()\n","            (activation_dropout_module): FairseqDropout()\n","            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          )\n","          (2): TransformerEncoderLayerBase(\n","            (self_attn): MultiheadAttention(\n","              (dropout_module): FairseqDropout()\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout_module): FairseqDropout()\n","            (activation_dropout_module): FairseqDropout()\n","            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          )\n","          (3): TransformerEncoderLayerBase(\n","            (self_attn): MultiheadAttention(\n","              (dropout_module): FairseqDropout()\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout_module): FairseqDropout()\n","            (activation_dropout_module): FairseqDropout()\n","            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          )\n","          (4): TransformerEncoderLayerBase(\n","            (self_attn): MultiheadAttention(\n","              (dropout_module): FairseqDropout()\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout_module): FairseqDropout()\n","            (activation_dropout_module): FairseqDropout()\n","            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          )\n","          (5): TransformerEncoderLayerBase(\n","            (self_attn): MultiheadAttention(\n","              (dropout_module): FairseqDropout()\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout_module): FairseqDropout()\n","            (activation_dropout_module): FairseqDropout()\n","            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          )\n","          (6): TransformerEncoderLayerBase(\n","            (self_attn): MultiheadAttention(\n","              (dropout_module): FairseqDropout()\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout_module): FairseqDropout()\n","            (activation_dropout_module): FairseqDropout()\n","            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          )\n","          (7): TransformerEncoderLayerBase(\n","            (self_attn): MultiheadAttention(\n","              (dropout_module): FairseqDropout()\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout_module): FairseqDropout()\n","            (activation_dropout_module): FairseqDropout()\n","            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          )\n","          (8): TransformerEncoderLayerBase(\n","            (self_attn): MultiheadAttention(\n","              (dropout_module): FairseqDropout()\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout_module): FairseqDropout()\n","            (activation_dropout_module): FairseqDropout()\n","            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          )\n","          (9): TransformerEncoderLayerBase(\n","            (self_attn): MultiheadAttention(\n","              (dropout_module): FairseqDropout()\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout_module): FairseqDropout()\n","            (activation_dropout_module): FairseqDropout()\n","            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          )\n","          (10): TransformerEncoderLayerBase(\n","            (self_attn): MultiheadAttention(\n","              (dropout_module): FairseqDropout()\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout_module): FairseqDropout()\n","            (activation_dropout_module): FairseqDropout()\n","            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          )\n","          (11): TransformerEncoderLayerBase(\n","            (self_attn): MultiheadAttention(\n","              (dropout_module): FairseqDropout()\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout_module): FairseqDropout()\n","            (activation_dropout_module): FairseqDropout()\n","            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          )\n","        )\n","      )\n","      (lm_head): RobertaLMHead(\n","        (dense): Linear(in_features=768, out_features=768, bias=True)\n","        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      )\n","    )\n","    (classification_heads): ModuleDict()\n","  )\n",")"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["masked_line = 'Quelle est votre <mask> ?'\n","camembert.fill_mask(masked_line,topk=15)"],"metadata":{"id":"LXQppaOEpl_n","executionInfo":{"status":"ok","timestamp":1652016936205,"user_tz":-120,"elapsed":10,"user":{"displayName":"Hika Chou","userId":"12770496042228956078"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d97a2823-1446-49de-88a7-38d698f33702"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('Quelle est votre expérience ?', 0.08961806446313858, ' expérience'),\n"," ('Quelle est votre spécialité ?', 0.07944537699222565, ' spécialité'),\n"," ('Quelle est votre passion ?', 0.06080527976155281, ' passion'),\n"," ('Quelle est votre profession ?', 0.05311649292707443, ' profession'),\n"," ('Quelle est votre devise ?', 0.035945046693086624, ' devise'),\n"," ('Quelle est votre personnalité ?', 0.028544200584292412, ' personnalité'),\n"," ('Quelle est votre philosophie ?', 0.026776568964123726, ' philosophie'),\n"," ('Quelle est votre histoire ?', 0.02547663077712059, ' histoire'),\n"," ('Quelle est votre opinion ?', 0.021505216136574745, ' opinion'),\n"," ('Quelle est votre formation ?', 0.02017086371779442, ' formation'),\n"," ('Quelle est votre mission ?', 0.016450250521302223, ' mission'),\n"," ('Quelle est votre situation ?', 0.016019070520997047, ' situation'),\n"," ('Quelle est votre fonction ?', 0.015977296978235245, ' fonction'),\n"," ('Quelle est votre motivation ?', 0.013968178071081638, ' motivation'),\n"," ('Quelle est votre recherche ?', 0.012540880590677261, ' recherche')]"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["masked_line = 'Demain il arrive pas <mask> '\n","camembert.fill_mask(masked_line,topk=15)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J-R7ibEaevnc","executionInfo":{"status":"ok","timestamp":1652016936645,"user_tz":-120,"elapsed":447,"user":{"displayName":"Hika Chou","userId":"12770496042228956078"}},"outputId":"5be57495-3d1f-4faf-a85e-3459b90c6f4b"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('Demain il arrive pas ! ', 0.2806454598903656, ' !'),\n"," ('Demain il arrive pas ... ', 0.12576186656951904, ' ...'),\n"," ('Demain il arrive pas encore ', 0.06877119094133377, ' encore'),\n"," ('Demain il arrive pas !!! ', 0.0548524484038353, ' !!!'),\n"," ('Demain il arrive pas !! ', 0.04346628487110138, ' !!'),\n"," ('Demain il arrive pas mal ', 0.02744949981570244, ' mal'),\n"," ('Demain il arrive pas ? ', 0.024653254076838493, ' ?'),\n"," ('Demain il arrive pas tard ', 0.017723912373185158, ' tard'),\n"," ('Demain il arrive pas loin ', 0.014308351092040539, ' loin'),\n"," ('Demain il arrive pas !!!! ', 0.013921571895480156, ' !!!!'),\n"," ('Demain il arrive pas cher ', 0.013326996937394142, ' cher'),\n"," ('Demain il arrive pas .... ', 0.011871535331010818, ' ....'),\n"," ('Demain il arrive pas moi ', 0.009495842270553112, ' moi'),\n"," ('Demain il arrive pas ici ', 0.007254695985466242, ' ici'),\n"," ('Demain il arrive pas là ', 0.005850363988429308, ' là')]"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["camembert.fill_mask(\"Hisser les voiles, <mask>!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"in3x9ELUg3iH","executionInfo":{"status":"ok","timestamp":1652016936647,"user_tz":-120,"elapsed":16,"user":{"displayName":"Hika Chou","userId":"12770496042228956078"}},"outputId":"6e5e5578-ebc1-4b63-8a78-84e4598d75c6"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('Hisser les voiles, bonjour!', 0.09438372403383255, ' bonjour'),\n"," ('Hisser les voiles, maintenant!', 0.04255270957946777, ' maintenant'),\n"," ('Hisser les voiles, oui!', 0.03574129939079285, ' oui'),\n"," ('Hisser les voiles, enfin!', 0.030704302713274956, ' enfin'),\n"," ('Hisser les voiles, voilà!', 0.029116446152329445, ' voilà')]"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["camembert.fill_mask(\"Rendez nous <mask> !\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5r8Fm2KshGgw","executionInfo":{"status":"ok","timestamp":1652016936648,"user_tz":-120,"elapsed":13,"user":{"displayName":"Hika Chou","userId":"12770496042228956078"}},"outputId":"a885566a-77a9-450d-e0a4-b918071a0e1d"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('Rendez nous visite !', 0.48574626445770264, ' visite'),\n"," ('Rendez nous demain !', 0.05029233545064926, ' demain'),\n"," ('Rendez nous compte !', 0.03767026960849762, ' compte'),\n"," ('Rendez nous nombreux !', 0.03340661898255348, ' nombreux'),\n"," ('Rendez nous célèbre !', 0.030758218839764595, ' célèbre')]"]},"metadata":{},"execution_count":7}]}]}